{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3aaffb-6237-4d33-ad74-d518f4870cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shubham/Documents/questions_pro_bot/ll_venv\n"
     ]
    }
   ],
   "source": [
    "#check if venv is used correctly\n",
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d79e7e69-c5c7-47f7-b86c-ee98d43cfabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shubham/Documents/questions_pro_bot'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7625c1e-e859-4435-a2aa-194917e451e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 freeze | grep ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db09fe83-d631-4b45-ad0d-87588cd8782f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install langchain_community langchain_text_splitters\n",
    "# !pip3 install pypdf\n",
    "# !brew install libmagic\n",
    "# !pip3 install python-docx\n",
    "# !pip3 install sentence-transformers\n",
    "# !pip3 install langchain-chroma\n",
    "# !pip3 install transformers -U\n",
    "# !pip3 install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4e78e-ad3f-4a17-b771-3323ed208612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3469e16d-4ed0-4c70-972e-96e0e1eaaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader # for PDFs\n",
    "from docx import Document # for doc or docx \n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "import warnings\n",
    "\n",
    "# from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6766f43a-f0fe-4d37-bf53-9b48a650d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "file_path = 'documents/mentalhealthmonth21.docx' # input(\"Enter full file path for your document (as of now supported - csv, pdf, doc or docx) : \")\n",
    "file_name, file_extension = os.path.splitext(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f04a5eb-08be-4ca2-989b-4fef2c99443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exist and is supported.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(file_path) and file_extension.lower() in ['.csv', '.pdf', '.docx']:\n",
    "    print(\"File exist and is supported.\")\n",
    "else :\n",
    "    raise Exception(\"Either file don't exist or is not supported - give full file path for your document (as of now supported - csv, pdf, doc or docx).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "662db82c-529a-4972-8674-e9cab77e0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af8781-9983-4f6f-8108-87d3af716211",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_extension.lower() == '.pdf':\n",
    "    loaded_pdf = PyPDFLoader(file_path).load()\n",
    "    splitted_text = text_splitter.split_documents(loaded_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31244d02-5765-4465-aad9-a187e443a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if file_extension.lower() == '.docx':\n",
    "    docx = Document(file_path)\n",
    "    docx_text = \"\\n\".join([p.text for p in docx.paragraphs])\n",
    "    splitted_text = text_splitter.split_text(docx_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5995a172-d9bb-4747-9cdd-c1ded34eddb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_text) #, len(loaded_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ad2e1f-b2e4-48d7-8b8c-0780b4e3c3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\", show_progress=True)\n",
    "# embedding_function = OllamaEmbeddings(model=\"llama3.2:latest\", show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b5bcb1-a4fe-4447-8e4c-dd7f00729fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████████| 9/9 [00:07<00:00,  1.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = Chroma.from_texts(splitted_text, embedding_function, persist_directory='chromadb_dir')\n",
    "# db = Chroma.from_documents(splitted_text, embedding_function, persist_directory='chromadb_dir')\n",
    "db._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c592fd3-d6bc-4146-af69-ce5b0b21586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = db2.similarity_search_with_score(query=\"who is the queen of herbs?\", k=3) # The similarity_search_with_score function in LangChain with Chroma DB returns higher scores for less relevant documents because it uses cosine distance as the scoring metric. In cosine distance, a lower score indicates a higher similarity between the query and the document. Therefore, documents with lower scores are more relevant to the query.\n",
    "# results\n",
    "# results[0][0].page_content\n",
    "# results[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b78bec-afcb-4fb1-b3b6-2895750eca3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████████| 1/1 [00:01<00:00,  1.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={}, page_content='Quick Post 3: \\nYou are not alone. Now more than ever, we need to find ways to stay connected with each other, and our community. No one should feel alone or without the information, support and help they need. Reach out to a family, friend or neighbor. The National Suicide Prevention Lifeline is available for support 24/7 at 1-800-237-8255 or text MN to 741741. #StayConnectedMN #MHAM\\nQuick Post 4:'),\n",
       "  -4735.620394899524),\n",
       " (Document(metadata={}, page_content='For more posts, emails, and messages, check out our #StayConnectedMN Toolkit, which focuses on mental well-being during the COVID-19 pandemic.\\nEmail\\nEmails can be shared throughout an organization to provide information on mental health awareness. \\nTaking care of yourself during Mental Health Awareness Month\\nMental health is all around us, but, what exactly is mental health? Mental health is a person’s general sense of emotional, psychological, and cognitive well-being. Everyone has mental health every day, but it’s often ignored unless something is going seriously wrong. The best way to prevent that is to pay attention to your mental health even when you are feeling okay or even good.'),\n",
       "  -5128.348269047789),\n",
       " (Document(metadata={}, page_content='If you, or someone you know, are in crisis, please call the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or text MN to 741741. You are not alone and someone is always available to talk.\\nQuick Posts\\nQuick posts are short messages that can be shared on social media and/or on an employee intranet or message board. These messages are brief and to the point. Adding graphics or images can enhance your post. \\nQuick Post 1: \\nMental Health is essential to everyone’s overall health and well-being, and mental illnesses are common and treatable. It is easy to ignore the body indicators of poor mental well-being – consistent tense neck, poor sleep, and feeling irritable are some cues. Take time to focus on what your body is telling you. The COVID-19 Wellness Pocket Guide provides tips and ideas for taking care of yourself and your family. #StayConnectedMN #MHAM https://www.health.state.mn.us/diseases/coronavirus/hcp/mhpocket.pdf\\nQuick Post 2:'),\n",
       "  -5485.406345414983)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = db.similarity_search_with_relevance_scores(query=\"What can be done for mental health awareness ?\", k=3) # Return docs and relevance scores in the range [0, 1].0 is dissimilar, 1 is most similar.\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1440c8-fa11-48ea-aa66-476733b3487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity: Measures the cosine of the angle between vectors, indicating their similarity. Higher values mean greater similarity.\n",
    "\n",
    "# Cosine Distance: Measures the dissimilarity between vectors as the complement of the cosine similarity. Higher values mean greater dissimilarity.\n",
    "\n",
    "# cosine_similarity(A, B) = (A . B) / (||A|| * ||B||)\n",
    "# cosine_distance(A, B) = 1 - cosine_similarity(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e96d3f-cd43-4989-84ce-5b51b49d7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "dir = 'chromadb_dir'\n",
    "if os.path.exists(dir):\n",
    "    shutil.rmtree(dir)\n",
    "os.makedirs(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded446ea-91a2-478a-a7f2-c408bbff04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = Chroma(persist_directory='chromadb_dir', embedding_function=embedding_function)\n",
    "db2._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5fadbc-3133-43fb-bce5-8c55fae4a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fe5341-58c8-4c11-a021-b48c96cddde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = []\n",
    "context_str = \"\"\n",
    "for i, result in enumerate(results) :\n",
    "    if 0 <= result[1] <= 1:\n",
    "        context = result[0].page_content.replace(\" \\n\", \" \")\n",
    "        contexts.append(context)\n",
    "        # if i == 0 : \n",
    "        #     context = \"Contexts : \\n\\n\\tA] High Relevance Context :\\n\" + context\n",
    "        # elif i == 1 : \n",
    "        #     context = \"\\n\\tB] Medium Relevance Context :\\n\" + context\n",
    "        # elif i == 2 : \n",
    "        #     context = \"\\n\\tC] Low Relevance Context :\\n\" + context\n",
    "        context_str = context_str + \"\\n\" + context\n",
    "print(context_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914c1aca-edfa-4121-8a02-4cc4add7f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is REISHI ??\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are chat bot who answers the Question by using the Contexts provided below.\n",
    "{context_str}\n",
    "\n",
    "Question: {question} \n",
    "DO NOT justify your answers. DO NOT give information not mentioned in the Contexts info above.\n",
    "\n",
    "Your Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4536826c-2675-4eba-b5ca-21535a5e5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cc6ac5-fe33-4265-bafd-f6d6de800578",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"WHAT HAPPENS DURING T’AI CHI?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "* You are chat bot who answers the Question by using the Contexts given to you.\n",
    "\n",
    "* Contexts :{context_str}\n",
    "\n",
    "* Question you have to answer based on above Contexts : {question} \n",
    "\n",
    "* Your Answer:\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a692abb-81ff-4bbc-b377-68e63c2454b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# API endpoint\n",
    "OLLAMA_API_URL = \"http://localhost:11434/api/chat\"\n",
    "\n",
    "def send_prompt_to_llama(prompt, model=\"llama3.2:latest\"):\n",
    "    \"\"\"\n",
    "    Send a prompt to the LLaMA model via Ollama API with streaming disabled.\n",
    "    \"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False  # Disable streaming to get the full response at once\n",
    "    }\n",
    "\n",
    "    # Send request to Ollama\n",
    "    response = requests.post(OLLAMA_API_URL, json=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        return response_data[\"message\"].get(\"content\", \"No response from model.\")\n",
    "    else:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "# Example Usage\n",
    "response = send_prompt_to_llama(prompt)\n",
    "print(\"Bot Response:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884e2f1-fb70-4379-8039-2eae342f7e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamalenseVENV3.11.6",
   "language": "python",
   "name": "ll_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
